{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "GPU_ID= '0'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =GPU_ID\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\envs\\python36\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# ^^^ pyforest auto-imports - don't write above this line\n",
    "# example of loading a pix2pix model and using it for image to image translation\n",
    "from keras.models import load_model\n",
    "from numpy import load\n",
    "from numpy import vstack\n",
    "from matplotlib import pyplot\n",
    "from numpy.random import randint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(array):\n",
    "    array_min, array_max = array.min(), array.max()\n",
    "    return ((array - array_min) / (array_max - array_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^ pyforest auto-imports - don't write above this line\n",
    "# load and prepare training images\n",
    "def load_real_samples(training_patches):\n",
    "    # load compressed arrays\n",
    "    X1= np.zeros((len(training_patches),256,256,3))\n",
    "    X2= np.zeros((len(training_patches),256,256,8))\n",
    "    for i,(filename, state) in enumerate(training_patches):\n",
    "        data = np.load(filename)\n",
    "        # unpack arrays\n",
    "        redn = normalize(data[:, :, 0])\n",
    "        greenn = normalize(data[:, :, 1])\n",
    "        bluen = normalize(data[:, :, 2])\n",
    "        #infraredn = normalize(data[:, :, 3])\n",
    "        X1[i] = np.dstack((redn, greenn, bluen))\n",
    "        #X2[i] = np.copy(np.expand_dims(data[:, :, 5],axis=2))\n",
    "        y_train_hr = np.copy(data[:, :, 5])\n",
    "        y_train_hr[y_train_hr == 1] = 0\n",
    "        y_train_hr[y_train_hr == 2] = 1\n",
    "        y_train_hr[y_train_hr == 4] = 2\n",
    "        y_train_hr[y_train_hr == 5] = 3\n",
    "        y_train_hr[y_train_hr == 6] = 4\n",
    "        y_train_hr[y_train_hr == 7] = 5\n",
    "        y_train_hr[y_train_hr == 9] = 6\n",
    "        y_train_hr[y_train_hr == 10] = 7\n",
    "        y_train_hr = keras.utils.to_categorical(y_train_hr, 8)\n",
    "        X2[i] = y_train_hr\n",
    "    return [X1, X2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^ pyforest auto-imports - don't write above this line\n",
    "data_dir = '../SEN12MS/processed/'\n",
    "training_states = ['ROIs13_high_roshan_s2']\n",
    "validation_states = ['ROIs13_high_roshan_s2']\n",
    "training_patches=[]\n",
    "for state in training_states:\n",
    "    fn= os.path.join(data_dir,'%s_train_patches/' %state)\n",
    "    #print(fn)\n",
    "    with os.scandir(fn) as entries:\n",
    "        for entry in entries:\n",
    "            #print(entry.name)\n",
    "            with os.scandir(fn+entry.name) as folders:\n",
    "                for folder in folders:\n",
    "                    #print(folder.name)\n",
    "                    with os.scandir(fn+entry.name+'/'+folder.name) as files:\n",
    "                        for file in files:\n",
    "                            #print(file.name)\n",
    "                            training_patches.append((os.path.join(fn+entry.name+'/'+folder.name+'/',file.name),state))\n",
    "#print(training_patches)\n",
    "\n",
    "validation_patches=[]\n",
    "for state in validation_states:\n",
    "    fn= os.path.join(data_dir,'%s_val_patches/' %state)\n",
    "    #print(fn)\n",
    "    with os.scandir(fn) as entries:\n",
    "        for entry in entries:\n",
    "            #print(entry.name)\n",
    "            with os.scandir(fn+entry.name) as folders:\n",
    "                for folder in folders:\n",
    "                    #print(folder.name)\n",
    "                    with os.scandir(fn+entry.name+'/'+folder.name) as files:\n",
    "                        for file in files:\n",
    "                            #print(file.name)\n",
    "                            validation_patches.append((os.path.join(fn+entry.name+'/'+folder.name+'/',file.name),state))\n",
    "#print(validation_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SEN12MS/processed/ROIs13_high_roshan_s2_val_patches/ROIs13_high_roshan/s2_1/ROIs0000_validation_s2_0_p1001.npy\n"
     ]
    }
   ],
   "source": [
    "print(validation_patches[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-4b8c35d56156>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_real_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_patches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-b21df304123a>\u001b[0m in \u001b[0;36mload_real_samples\u001b[1;34m(training_patches)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mX1\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_patches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mX2\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_patches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_patches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# unpack arrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "[X1, X2] = load_real_samples(validation_patches[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loaded', X1.shape, X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_172980.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting a random exmaple\n",
    "ix = randint(0, len(X1), 1)\n",
    "src_image, tar_image = X1[ix], X2[ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_image = model.predict(src_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab2rgb = {0:[0./255, 128./255, 0./255],        #dark-green         ->          Forest\n",
    "           1:[205./255, 133./255, 63./255],     #peruvian-brown     ->          Dense-Shrublands\n",
    "           2:[224./255, 216./255, 202./255],    #savana-oaks        ->          Woody-Savanas\n",
    "           3:[102./255, 102./255, 25./255],    #dark-olive         ->          Grasslands\n",
    "           4:[210./255, 209./255, 205./255],   #concrete           ->          Urban\n",
    "           #5:[229./255, 229./255, 178./255],   #pale-olive         ->          Vegetation\n",
    "           5:[255./255, 255./255, 255./255],   #white              ->          Snow-and-ice\n",
    "           6:[131./255, 117./255, 96./255],    #barren-paint       ->          Barren\n",
    "           7:[135./255, 206./255, 250./255],   #light-blue         ->          Water-bodies\n",
    "          }\n",
    "rgb = np.ones((256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot source, generated and target images\n",
    "def plot_images(src_img, gen_img, tar_img):\n",
    "    #images = vstack((src_img, gen_img, tar_img))\n",
    "    # scale from [-1,1] to [0,1]\n",
    "    #images = (images + 1) / 2.0\n",
    "    #titles = ['Source', 'Generated', 'Expected']\n",
    "    # plot images row by row\n",
    "    \n",
    "    n_samples =1\n",
    "    for i in range(n_samples):\n",
    "        pyplot.subplot(3, n_samples, 1 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(src_img[i])\n",
    "    # plot generated target image\n",
    "    for i in range(n_samples):\n",
    "        label = np.argmax(gen_img[i], axis=-1)\n",
    "        for p in range(256):\n",
    "            for q in range(256):\n",
    "                rgb[p,q,:] = np.expand_dims(np.array(lab2rgb[label[p,q]]),axis=0)\n",
    "        pyplot.subplot(3, n_samples, 1 + n_samples + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(rgb)\n",
    "    # plot real target image\n",
    "    for i in range(n_samples):\n",
    "        label = np.argmax(tar_img[i], axis=-1)\n",
    "        for p in range(256):\n",
    "            for q in range(256):\n",
    "                rgb[p,q,:] = np.expand_dims(np.array(lab2rgb[label[p,q]]),axis=0)\n",
    "        pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
    "        pyplot.axis('off')\n",
    "        pyplot.imshow(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(src_image, gen_image, tar_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
